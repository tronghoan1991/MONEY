import os
import pandas as pd
import psycopg2
from sqlalchemy import create_engine
from telegram import Update
from telegram.ext import (
    Application, CommandHandler, MessageHandler, filters, ContextTypes
)
from datetime import datetime
import re
import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import numpy as np
from flask import Flask
import threading
import warnings

# ==== CONFIG ====
BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
MIN_BATCH = 5
ROLLING_WINDOW = 50
PROBA_CUTOFF = 0.62
PROBA_ALERT = 0.75
BAO_CUTOFF = 0.03
TRAIN_EVERY = 5  # Chá»‰ train láº¡i model khi cÃ³ >=5 phiÃªn má»›i

MODEL_PATH = "ml_stack.joblib"
MODEL_META = "ml_meta.txt"
SESSION_FILE = "session_time.txt"
LAST_PLAY_FILE = "last_play_time.txt"
MIN_SESSION_INPUT = 10      # Sá»‘ phiÃªn tá»‘i Ä‘a cáº§n nháº­p Ä‘á»ƒ báº¯t trend má»›i
SESSION_BREAK_MINUTES = 30  # Bao nhiÃªu phÃºt nghá»‰ thÃ¬ bot coi lÃ  session má»›i

if not BOT_TOKEN or not DATABASE_URL:
    raise Exception("Báº¡n cáº§n set BOT_TOKEN vÃ  DATABASE_URL á»Ÿ biáº¿n mÃ´i trÆ°á»ng!")

# ==== FLASK giá»¯ cá»•ng Ä‘á»ƒ trÃ¡nh sleep ====
def start_flask():
    app = Flask(__name__)

    @app.route('/')
    def home():
        return "Bot is alive!", 200

    @app.route('/healthz')
    def health():
        return "OK", 200

    app.run(host='0.0.0.0', port=10000)

threading.Thread(target=start_flask, daemon=True).start()

# ==== DB ====
def create_table():
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    # Táº¡o báº£ng náº¿u chÆ°a cÃ³
    cur.execute("""
        CREATE TABLE IF NOT EXISTS history (
            id SERIAL PRIMARY KEY,
            input TEXT,
            actual TEXT,
            created_at TIMESTAMP DEFAULT NOW(),
            bot_predict TEXT
        );
    """)
    conn.commit()
    cur.close()
    conn.close()

def insert_result(input_str, actual, bot_predict=None):
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    now = datetime.now()
    if bot_predict is not None:
        cur.execute(
            "INSERT INTO history (input, actual, bot_predict, created_at) VALUES (%s, %s, %s, %s);",
            (input_str, actual, bot_predict, now)
        )
    else:
        cur.execute(
            "INSERT INTO history (input, actual, created_at) VALUES (%s, %s, %s);",
            (input_str, actual, now)
        )
    conn.commit()
    cur.close()
    conn.close()

def fetch_history(limit=10000):
    # Sá»­ dá»¥ng SQLAlchemy Ä‘á»ƒ trÃ¡nh warning pandas!
    engine = create_engine(DATABASE_URL)
    df = pd.read_sql(
        "SELECT input, actual, bot_predict, created_at FROM history ORDER BY id ASC LIMIT %s" % limit,
        engine
    )
    engine.dispose()
    # Chá»‰ láº¥y cÃ¡c dÃ²ng input lÃ  3 sá»‘
    df = df[df['input'].str.match(r"^\d+\s+\d+\s+\d+$", na=False)]
    return df

def delete_all_history():
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    cur.execute("TRUNCATE TABLE history;")
    conn.commit()
    cur.close()
    conn.close()

def make_features(df):
    df = df[df['input'].str.match(r"^\d+\s+\d+\s+\d+$", na=False)].copy()
    df['total'] = df['input'].apply(lambda x: sum([int(i) for i in x.split()]))
    df['even'] = df['total'] % 2
    df['bao'] = df['input'].apply(lambda x: 1 if len(set(x.split()))==1 else 0)
    df['tai'] = (df['total'] >= 11).astype(int)
    df['xiu'] = (df['total'] <= 10).astype(int)
    df['chan'] = (df['even'] == 0).astype(int)
    df['le'] = (df['even'] == 1).astype(int)
    df['tai_roll'] = df['tai'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['xiu_roll'] = df['xiu'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['chan_roll'] = df['chan'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['le_roll'] = df['le'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['bao_roll'] = df['bao'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    return df

def train_models(df):
    X = df[['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    y_tx = (df['total'] >= 11).astype(int)
    y_cl = (df['even'] == 0).astype(int)
    y_bao = df['bao']
    models = {}
    for key, y in [('tx', y_tx), ('cl', y_cl), ('bao', y_bao)]:
        if len(set(y)) < 2:
            models[key] = None
            continue
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            lr = LogisticRegression().fit(X, y)
            rf = RandomForestClassifier(n_estimators=100).fit(X, y)
            xgbc = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss').fit(X, y)
        models[key] = (lr, rf, xgbc)
    joblib.dump(models, MODEL_PATH)
    # LÆ°u sá»‘ lÆ°á»£ng phiÃªn thá»±c táº¿ Ä‘Ã£ train vÃ o file meta
    with open(MODEL_META, "w") as f:
        f.write(str(len(df)))

def load_models():
    if not os.path.exists(MODEL_PATH):
        return None
    return joblib.load(MODEL_PATH)

def summary_stats(df):
    if 'bot_predict' in df.columns:
        df_pred = df[df['bot_predict'].notnull()]
        so_du_doan = len(df_pred)
        dung = (df_pred['bot_predict'] == df_pred['actual']).sum()
        sai = so_du_doan - dung
        tile = round((dung / so_du_doan) * 100, 2) if so_du_doan else 0
        return so_du_doan, dung, sai, tile
    else:
        return 0, 0, 0, 0

def suggest_best_totals(df, prediction):
    if prediction not in ("TÃ i", "Xá»‰u") or df.empty:
        return "-"
    recent = df.tail(ROLLING_WINDOW)
    totals = [sum(int(x) for x in s.split()) for s in recent['input'] if s]
    if prediction == "TÃ i":
        eligible = [t for t in range(11, 19)]
    else:
        eligible = [t for t in range(3, 11)]
    count = pd.Series([t for t in totals if t in eligible]).value_counts()
    if count.empty:
        return "-"
    best = count.index[:3].tolist()
    if not best:
        return "-"
    return f"{min(best)}â€“{max(best)}"

def predict_stacking(X_pred, models, key):
    if models[key] is None:
        return 0.5, [0.5, 0.5, 0.5]
    lr, rf, xgbc = models[key]
    prob_lr = lr.predict_proba(X_pred)[0][1]
    prob_rf = rf.predict_proba(X_pred)[0][1]
    prob_xgb = xgbc.predict_proba(X_pred)[0][1]
    probs = np.array([prob_lr, prob_rf, prob_xgb])
    return probs.mean(), probs

PENDING_RESET = {}

def save_session_start(time=None):
    with open(SESSION_FILE, "w") as f:
        t = time if time else datetime.now().isoformat()
        f.write(str(t))

def load_session_start():
    if not os.path.exists(SESSION_FILE):
        return None
    with open(SESSION_FILE, "r") as f:
        t = f.read().strip()
    try:
        return datetime.fromisoformat(t)
    except Exception:
        return None

def save_last_play(time=None):
    with open(LAST_PLAY_FILE, "w") as f:
        t = time if time else datetime.now().isoformat()
        f.write(str(t))

def load_last_play():
    if not os.path.exists(LAST_PLAY_FILE):
        return None
    with open(LAST_PLAY_FILE, "r") as f:
        t = f.read().strip()
    try:
        return datetime.fromisoformat(t)
    except Exception:
        return None

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()
    create_table()
    # XÃ¡c nháº­n lá»‡nh reset
    if user_id in PENDING_RESET and PENDING_RESET[user_id]:
        if text.upper() == "XÃ“A Háº¾T":
            delete_all_history()
            PENDING_RESET[user_id] = False
            await update.message.reply_text("âœ… ÄÃ£ xÃ³a toÃ n bá»™ dá»¯ liá»‡u lá»‹ch sá»­.")
        else:
            PENDING_RESET[user_id] = False
            await update.message.reply_text("âŒ Há»§y thao tÃ¡c xÃ³a.")
        return

    now = datetime.now()
    last_play = load_last_play()
    session_start = load_session_start()
    need_new_session = False
    minutes_since_last = None

    # Check náº¿u cÃ³ last_play
    if last_play:
        delta = (now - last_play).total_seconds() / 60
        minutes_since_last = int(delta)
        if delta >= SESSION_BREAK_MINUTES:
            need_new_session = True
    else:
        need_new_session = True

    # Náº¿u cáº§n báº¯t Ä‘áº§u session má»›i tá»± Ä‘á»™ng
    if need_new_session:
        save_session_start(now)
        if minutes_since_last:
            await update.message.reply_text(
                f"â° Báº¡n Ä‘Ã£ khÃ´ng chÆ¡i trong {minutes_since_last} phÃºt. "
                f"HÃ£y nháº­p tá»‘i Ä‘a {MIN_SESSION_INPUT} phiÃªn má»›i Ä‘á»ƒ bot báº¯t láº¡i trend session!"
            )
        else:
            await update.message.reply_text(
                f"â° Báº¯t Ä‘áº§u session má»›i! HÃ£y nháº­p tá»‘i Ä‘a {MIN_SESSION_INPUT} phiÃªn má»›i Ä‘á»ƒ bot báº¯t láº¡i trend."
            )

    # Update láº¡i thá»i gian chÆ¡i má»›i nháº¥t
    save_last_play(now)

    m = re.match(r"^(\d{3})$", text)
    m2 = re.match(r"^(\d+)\s+(\d+)\s+(\d+)$", text)
    if not (m or m2):
        await update.message.reply_text("Vui lÃ²ng nháº­p káº¿t quáº£ theo Ä‘á»‹nh dáº¡ng: 456 hoáº·c 4 5 6.")
        return
    numbers = [int(x) for x in (m.group(1) if m else " ".join([m2.group(1), m2.group(2), m2.group(3)]))]
    input_str = f"{numbers[0]} {numbers[1]} {numbers[2]}"
    total = sum(numbers)
    actual = "TÃ i" if total >= 11 else "Xá»‰u"

    # Láº¥y dá»± Ä‘oÃ¡n gáº§n nháº¥t (náº¿u cÃ³)
    df = fetch_history(10000)
    last_predict = None
    if len(df) > 0 and df.iloc[-1]['bot_predict']:
        last_predict = df.iloc[-1]['bot_predict']

    insert_result(input_str, actual, last_predict)

    # Äá»c láº¡i lá»‹ch sá»­ thá»±c táº¿
    df = fetch_history(10000)
    session_start = load_session_start()
    if session_start:
        df_session = df[df['created_at'] >= session_start]
    else:
        df_session = df
    if len(df_session) < MIN_SESSION_INPUT:
        await update.message.reply_text(f"Báº¡n cáº§n nháº­p tá»‘i Ä‘a {MIN_SESSION_INPUT} phiÃªn má»›i (sau khi báº¯t Ä‘áº§u session) Ä‘á»ƒ bot báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n trend session hiá»‡n táº¡i!")
        return

    # Train model báº±ng toÃ n bá»™ lá»‹ch sá»­
    df_feat = make_features(df)
    n_trained = 0
    if os.path.exists(MODEL_META):
        with open(MODEL_META, "r") as f:
            try:
                n_trained = int(f.read())
            except:
                n_trained = 0
    if len(df) >= MIN_BATCH and (len(df) - n_trained >= TRAIN_EVERY):
        train_models(df_feat)
    models = load_models()
    if (models is None or 
        models['tx'] is None or
        models['cl'] is None):
        lines = []
        lines.append(f"âœ”ï¸ ÄÃ£ lÆ°u káº¿t quáº£: {''.join(str(n) for n in numbers)}")
        lines.append("âš ï¸ ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘a dáº¡ng Ä‘á»ƒ dá»± Ä‘oÃ¡n (lá»‹ch sá»­ cáº§n Ä‘á»§ cáº£ TÃ i/Xá»‰u vÃ  Cháºµn/Láº»). Nháº­p thÃªm cÃ¡c tá»•ng tháº¥p vÃ  cao, tá»•ng cháºµn/láº» Ä‘á»ƒ bot hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c!")
        await update.message.reply_text('\n'.join(lines))
        return

    # Dá»± Ä‘oÃ¡n rolling trend chá»‰ dá»±a trÃªn session hiá»‡n táº¡i
    df_feat_session = make_features(df_session)
    X_pred = df_feat_session.iloc[[-1]][['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    tx_proba, tx_probs = predict_stacking(X_pred, models, 'tx')
    tx = "TÃ i" if tx_proba >= 0.5 else "Xá»‰u"
    cl_proba, cl_probs = predict_stacking(X_pred, models, 'cl')
    cl = "Cháºµn" if cl_proba >= 0.5 else "Láº»"
    dai_diem = suggest_best_totals(df_session, tx)
    # BÃƒO chá»‰ dá»± Ä‘oÃ¡n náº¿u Ä‘Ã£ cÃ³ model
    bao_pct = "-"
    if models.get('bao') is not None:
        bao_proba, bao_probs = predict_stacking(X_pred, models, 'bao')
        bao_pct = round(bao_proba*100,2)
    else:
        bao_proba = None

    # LÆ°u láº¡i dá»± Ä‘oÃ¡n vÃ o DB Ä‘á»ƒ so sÃ¡nh Ä‘Ãºng/sai
    insert_result("BOT_PREDICT", None, tx)

    so_du_doan, dung, sai, tile = summary_stats(fetch_history(10000))
    lines = []
    lines.append(f"âœ”ï¸ ÄÃ£ lÆ°u káº¿t quáº£: {''.join(str(n) for n in numbers)}")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"ğŸ¯ Dá»± Ä‘oÃ¡n: {tx} | {cl}")
    else:
        lines.append("âš ï¸ Dá»± Ä‘oÃ¡n: NÃªn nghá»‰ phiÃªn nÃ y!")
    lines.append(f"Dáº£i Ä‘iá»ƒm nÃªn Ä‘Ã¡nh: {dai_diem}")
    if bao_pct != "-":
        lines.append(f"XÃ¡c suáº¥t ra bÃ£o: {bao_pct}%")
        if bao_proba and bao_proba >= BAO_CUTOFF and models['bao'] is not None:
            lines.append(f"â—ï¸Cáº¢NH BÃO: XÃ¡c suáº¥t bÃ£o cao ({bao_pct}%) â€“ cÃ¢n nháº¯c vÃ o bÃ£o!")
    else:
        lines.append(f"ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n bÃ£o.")
    if max(tx_proba, 1-tx_proba) >= PROBA_ALERT:
        lines.append(f"â—ï¸Cáº¢NH BÃO: XÃ¡c suáº¥t {tx} vÆ°á»£t {int(PROBA_ALERT*100)}% â€“ trend cá»±c máº¡nh!")
    lines.append(f"BOT Ä‘Ã£ dá»± Ä‘oÃ¡n: {so_du_doan} phiÃªn | ÄÃºng: {dung} | Sai: {sai} | Tá»‰ lá»‡ Ä‘Ãºng: {tile}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"Nháº­n Ä‘á»‹nh: Æ¯u tiÃªn {tx}, {cl}, dáº£i {dai_diem}. BÃ£o {bao_pct}% â€“ {'Æ°u tiÃªn' if bao_proba and bao_proba >= BAO_CUTOFF and models['bao'] is not None else 'khÃ´ng nÃªn Ä‘Ã¡nh'} bÃ£o.")
    else:
        lines.append("Nháº­n Ä‘á»‹nh: KhÃ´ng cÃ³ cá»­a Æ°u tháº¿, nÃªn nghá»‰.")
    await update.message.reply_text('\n'.join(lines))

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "ğŸ¤– ChÃ o má»«ng Ä‘áº¿n vá»›i Sicbo ML Bot!\n\n"
        "CÃ¡c lá»‡nh há»— trá»£:\n"
        "/start â€“ Xem hÆ°á»›ng dáº«n vÃ  danh sÃ¡ch lá»‡nh\n"
        "/predict â€“ Dá»± Ä‘oÃ¡n phiÃªn tiáº¿p theo\n"
        "/stats â€“ Thá»‘ng kÃª hiá»‡u suáº¥t dá»± Ä‘oÃ¡n\n"
        "/reset â€“ XÃ³a toÃ n bá»™ lá»‹ch sá»­ data (cáº§n xÃ¡c nháº­n)\n"
        "KhÃ´ng cáº§n nháº­p lá»‡nh session ná»¯a! Bot sáº½ tá»± Ä‘á»™ng nháº­n biáº¿t náº¿u báº¡n nghá»‰ lÃ¢u vÃ  nháº¯c báº¯t trend má»›i.\n\n"
        "Nháº­p 3 sá»‘ káº¿t quáº£ (vd: 456 hoáº·c 4 5 6) Ä‘á»ƒ lÆ°u vÃ  cáº­p nháº­t model.\n"
        f"Náº¿u nghá»‰ quÃ¡ {SESSION_BREAK_MINUTES} phÃºt, bot sáº½ tá»± Ä‘á»™ng yÃªu cáº§u nháº­p tá»‘i Ä‘a {MIN_SESSION_INPUT} phiÃªn Ä‘áº§u Ä‘á»ƒ báº¯t láº¡i trend session!"
    )
    await update.message.reply_text(msg)

async def predict(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000)
    session_start = load_session_start()
    if session_start:
        df_session = df[df['created_at'] >= session_start]
    else:
        df_session = df
    if len(df_session) < MIN_SESSION_INPUT:
        await update.message.reply_text(f"Báº¡n cáº§n nháº­p tá»‘i Ä‘a {MIN_SESSION_INPUT} phiÃªn má»›i (sau khi báº¯t Ä‘áº§u session) Ä‘á»ƒ bot báº¯t Ä‘áº§u dá»± Ä‘oÃ¡n trend session hiá»‡n táº¡i!")
        return
    df_feat = make_features(df)
    n_trained = 0
    if os.path.exists(MODEL_META):
        with open(MODEL_META, "r") as f:
            try:
                n_trained = int(f.read())
            except:
                n_trained = 0
    if len(df) - n_trained >= TRAIN_EVERY:
        train_models(df_feat)
    models = load_models()
    if (models is None or 
        models['tx'] is None or
        models['cl'] is None):
        await update.message.reply_text("âš ï¸ ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘a dáº¡ng Ä‘á»ƒ dá»± Ä‘oÃ¡n (lá»‹ch sá»­ cáº§n Ä‘á»§ cáº£ TÃ i/Xá»‰u vÃ  Cháºµn/Láº»). Nháº­p thÃªm cÃ¡c tá»•ng tháº¥p vÃ  cao, tá»•ng cháºµn/láº» Ä‘á»ƒ bot hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c!")
        return
    df_feat_session = make_features(df_session)
    X_pred = df_feat_session.iloc[[-1]][['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    tx_proba, _ = predict_stacking(X_pred, models, 'tx')
    cl_proba, _ = predict_stacking(X_pred, models, 'cl')
    tx = "TÃ i" if tx_proba >= 0.5 else "Xá»‰u"
    cl = "Cháºµn" if cl_proba >= 0.5 else "Láº»"
    dai_diem = suggest_best_totals(df_session, tx)
    bao_pct = "-"
    if models.get('bao') is not None:
        bao_proba, _ = predict_stacking(X_pred, models, 'bao')
        bao_pct = round(bao_proba*100,2)
    else:
        bao_proba = None
    insert_result("BOT_PREDICT", None, tx)
    so_du_doan, dung, sai, tile = summary_stats(fetch_history(10000))
    lines = []
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"ğŸ¯ Dá»± Ä‘oÃ¡n: {tx} | {cl}")
    else:
        lines.append("âš ï¸ Dá»± Ä‘oÃ¡n: NÃªn nghá»‰ phiÃªn nÃ y!")
    lines.append(f"Dáº£i Ä‘iá»ƒm nÃªn Ä‘Ã¡nh: {dai_diem}")
    if bao_pct != "-":
        lines.append(f"XÃ¡c suáº¥t ra bÃ£o: {bao_pct}%")
        if bao_proba and bao_proba >= BAO_CUTOFF and models['bao'] is not None:
            lines.append(f"â—ï¸Cáº¢NH BÃO: XÃ¡c suáº¥t bÃ£o cao ({bao_pct}%) â€“ cÃ¢n nháº¯c vÃ o bÃ£o!")
    else:
        lines.append(f"ChÆ°a Ä‘á»§ dá»¯ liá»‡u Ä‘á»ƒ dá»± Ä‘oÃ¡n bÃ£o.")
    if max(tx_proba, 1-tx_proba) >= PROBA_ALERT:
        lines.append(f"â—ï¸Cáº¢NH BÃO: XÃ¡c suáº¥t {tx} vÆ°á»£t {int(PROBA_ALERT*100)}% â€“ trend cá»±c máº¡nh!")
    lines.append(f"BOT Ä‘Ã£ dá»± Ä‘oÃ¡n: {so_du_doan} phiÃªn | ÄÃºng: {dung} | Sai: {sai} | Tá»‰ lá»‡ Ä‘Ãºng: {tile}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"Nháº­n Ä‘á»‹nh: Æ¯u tiÃªn {tx}, {cl}, dáº£i {dai_diem}. BÃ£o {bao_pct}% â€“ {'Æ°u tiÃªn' if bao_proba and bao_proba >= BAO_CUTOFF and models['bao'] is not None else 'khÃ´ng nÃªn Ä‘Ã¡nh'} bÃ£o.")
    else:
        lines.append("Nháº­n Ä‘á»‹nh: KhÃ´ng cÃ³ cá»­a Æ°u tháº¿, nÃªn nghá»‰.")
    await update.message.reply_text('\n'.join(lines))

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000)
    so_du_doan, dung, sai, tile = summary_stats(df)
    msg = (
        f"BOT Ä‘Ã£ dá»± Ä‘oÃ¡n: {so_du_doan} phiÃªn\n"
        f"ÄÃºng: {dung}\n"
        f"Sai: {sai}\n"
        f"Tá»‰ lá»‡ Ä‘Ãºng: {tile}%"
    )
    await update.message.reply_text(msg)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    PENDING_RESET[user_id] = True
    await update.message.reply_text(
        "âš ï¸ Báº¡n cÃ³ cháº¯c cháº¯n muá»‘n xÃ³a toÃ n bá»™ lá»‹ch sá»­ data? "
        "Náº¿u cháº¯c cháº¯n, reply: XÃ“A Háº¾T\n"
        "Náº¿u khÃ´ng, nháº­p báº¥t ká»³ kÃ½ tá»± nÃ o khÃ¡c Ä‘á»ƒ há»§y."
    )

def main():
    create_table()
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("predict", predict))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
