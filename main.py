import os
import pandas as pd
import psycopg2
from telegram import Update
from telegram.ext import (
    Application, CommandHandler, MessageHandler, filters, ContextTypes, ConversationHandler
)
from datetime import datetime
import re
import joblib
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import numpy as np
from flask import Flask
import threading

# ==== CONFIG ====
BOT_TOKEN = os.getenv("BOT_TOKEN")
DATABASE_URL = os.getenv("DATABASE_URL")
MIN_BATCH = 5
ROLLING_WINDOW = 50
PROBA_CUTOFF = 0.62
PROBA_ALERT = 0.75
BAO_CUTOFF = 0.03

MODEL_PATH = "ml_stack.joblib"

if not BOT_TOKEN or not DATABASE_URL:
    raise Exception("B·∫°n c·∫ßn set BOT_TOKEN v√† DATABASE_URL ·ªü bi·∫øn m√¥i tr∆∞·ªùng!")

# ==== FLASK gi·ªØ c·ªïng ƒë·ªÉ tr√°nh sleep ====
def start_flask():
    app = Flask(__name__)

    @app.route('/')
    def home():
        return "Bot is alive!", 200

    @app.route('/healthz')
    def health():
        return "OK", 200

    app.run(host='0.0.0.0', port=10000)

threading.Thread(target=start_flask, daemon=True).start()

# ==== DB ====
def create_table():
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    # Th√™m c·ªôt bot_predict n·∫øu ch∆∞a c√≥
    cur.execute("""
        CREATE TABLE IF NOT EXISTS history (
            id SERIAL PRIMARY KEY,
            input TEXT,
            actual TEXT,
            bot_predict TEXT,
            created_at TIMESTAMP DEFAULT NOW()
        );
    """)
    conn.commit()
    cur.close()
    conn.close()

def insert_result(input_str, actual, bot_predict=None):
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    now = datetime.now()
    if bot_predict is not None:
        cur.execute(
            "INSERT INTO history (input, actual, bot_predict, created_at) VALUES (%s, %s, %s, %s);",
            (input_str, actual, bot_predict, now)
        )
    else:
        cur.execute(
            "INSERT INTO history (input, actual, created_at) VALUES (%s, %s, %s);",
            (input_str, actual, now)
        )
    conn.commit()
    cur.close()
    conn.close()

def fetch_history(limit=10000):
    conn = psycopg2.connect(DATABASE_URL)
    df = pd.read_sql("SELECT input, actual, bot_predict, created_at FROM history ORDER BY id ASC LIMIT %s" % limit, conn)
    conn.close()
    return df

def delete_all_history():
    conn = psycopg2.connect(DATABASE_URL)
    cur = conn.cursor()
    cur.execute("TRUNCATE TABLE history;")
    conn.commit()
    cur.close()
    conn.close()

def make_features(df):
    df = df.copy()
    df['total'] = df['input'].apply(lambda x: sum([int(i) for i in x.split()]))
    df['even'] = df['total'] % 2
    df['bao'] = df['input'].apply(lambda x: 1 if len(set(x.split()))==1 else 0)
    df['tai'] = (df['total'] >= 11).astype(int)
    df['xiu'] = (df['total'] <= 10).astype(int)
    df['chan'] = (df['even'] == 0).astype(int)
    df['le'] = (df['even'] == 1).astype(int)
    df['tai_roll'] = df['tai'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['xiu_roll'] = df['xiu'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['chan_roll'] = df['chan'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['le_roll'] = df['le'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    df['bao_roll'] = df['bao'].rolling(ROLLING_WINDOW, min_periods=1).mean()
    return df

def train_models(df):
    X = df[['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    y_tx = (df['total'] >= 11).astype(int)
    y_cl = (df['even'] == 0).astype(int)
    y_bao = df['bao']
    models = {}
    for key, y in [('tx', y_tx), ('cl', y_cl), ('bao', y_bao)]:
        if len(set(y)) < 2:
            models[key] = None
            continue
        lr = LogisticRegression().fit(X, y)
        rf = RandomForestClassifier(n_estimators=100).fit(X, y)
        xgbc = xgb.XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss').fit(X, y)
        models[key] = (lr, rf, xgbc)
    joblib.dump(models, MODEL_PATH)

def load_models():
    if not os.path.exists(MODEL_PATH):
        return None
    return joblib.load(MODEL_PATH)

def predict_stacking(X_pred, models, key):
    if models[key] is None:
        return 0.5, [0.5, 0.5, 0.5]
    lr, rf, xgbc = models[key]
    prob_lr = lr.predict_proba(X_pred)[0][1]
    prob_rf = rf.predict_proba(X_pred)[0][1]
    prob_xgb = xgbc.predict_proba(X_pred)[0][1]
    probs = np.array([prob_lr, prob_rf, prob_xgb])
    return probs.mean(), probs

def summary_stats(df):
    if 'bot_predict' in df.columns:
        df_pred = df[df['bot_predict'].notnull()]
        so_du_doan = len(df_pred)
        dung = (df_pred['bot_predict'] == df_pred['actual']).sum()
        sai = so_du_doan - dung
        tile = round((dung / so_du_doan) * 100, 2) if so_du_doan else 0
        return so_du_doan, dung, sai, tile
    else:
        return 0, 0, 0, 0

def suggest_best_totals(df, prediction):
    if prediction not in ("T√†i", "X·ªâu") or df.empty:
        return "-"
    recent = df.tail(ROLLING_WINDOW)
    totals = [sum(int(x) for x in s.split()) for s in recent['input'] if s]
    if prediction == "T√†i":
        eligible = [t for t in range(11, 19)]
    else:
        eligible = [t for t in range(3, 11)]
    count = pd.Series([t for t in totals if t in eligible]).value_counts()
    if count.empty:
        return "-"
    best = count.index[:3].tolist()
    if not best:
        return "-"
    return f"{min(best)}‚Äì{max(best)}"

# ==== HANDLERS ====
PENDING_RESET = {}

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    text = update.message.text.strip()
    create_table()
    # X√°c nh·∫≠n l·ªánh reset
    if user_id in PENDING_RESET and PENDING_RESET[user_id]:
        if text.upper() == "X√ìA H·∫æT":
            delete_all_history()
            PENDING_RESET[user_id] = False
            await update.message.reply_text("‚úÖ ƒê√£ x√≥a to√†n b·ªô d·ªØ li·ªáu l·ªãch s·ª≠.")
        else:
            PENDING_RESET[user_id] = False
            await update.message.reply_text("‚ùå H·ªßy thao t√°c x√≥a.")
        return

    m = re.match(r"^(\d{3})$", text)
    m2 = re.match(r"^(\d+)\s+(\d+)\s+(\d+)$", text)
    if not (m or m2):
        await update.message.reply_text("Vui l√≤ng nh·∫≠p k·∫øt qu·∫£ theo ƒë·ªãnh d·∫°ng: 456 ho·∫∑c 4 5 6.")
        return
    numbers = [int(x) for x in (m.group(1) if m else " ".join([m2.group(1), m2.group(2), m2.group(3)]))]
    input_str = f"{numbers[0]} {numbers[1]} {numbers[2]}"
    total = sum(numbers)
    actual = "T√†i" if total >= 11 else "X·ªâu"

    # L·∫•y d·ª± ƒëo√°n g·∫ßn nh·∫•t (n·∫øu c√≥)
    df = fetch_history(10000)
    last_predict = None
    if len(df) > 0 and df.iloc[-1]['bot_predict']:
        last_predict = df.iloc[-1]['bot_predict']
    else:
        # N·∫øu kh√¥ng c√≥ bot_predict ·ªü d√≤ng cu·ªëi, t·ª± d·ª± ƒëo√°n l·∫°i
        df_feat = make_features(df)
        models = load_models()
        if models is not None:
            X_pred = df_feat.iloc[[-1]][['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
            tx_proba, _ = predict_stacking(X_pred, models, 'tx')
            last_predict = "T√†i" if tx_proba >= 0.5 else "X·ªâu"

    insert_result(input_str, actual, last_predict)

    # Train v√† d·ª± ƒëo√°n phi√™n ti·∫øp theo
    df = fetch_history(10000)
    df_feat = make_features(df)
    if len(df) >= MIN_BATCH:
        train_models(df_feat)
    models = load_models()
    if (models is None or 
        models['tx'] is None or
        models['cl'] is None or
        models['bao'] is None):
        lines = []
        lines.append(f"‚úîÔ∏è ƒê√£ l∆∞u k·∫øt qu·∫£: {''.join(str(n) for n in numbers)}")
        lines.append("‚ö†Ô∏è Ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒëa d·∫°ng ƒë·ªÉ d·ª± ƒëo√°n (l·ªãch s·ª≠ m·ªõi ch·ªâ c√≥ 1 lo·∫°i k·∫øt qu·∫£). Nh·∫≠p th√™m c·∫£ T√†i/X·ªâu, Ch·∫µn/L·∫ª, B√£o/Kh√¥ng b√£o ƒë·ªÉ bot ho·∫°t ƒë·ªông ch√≠nh x√°c!")
        await update.message.reply_text('\n'.join(lines))
        return
    X_pred = df_feat.iloc[[-1]][['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    tx_proba, tx_probs = predict_stacking(X_pred, models, 'tx')
    tx = "T√†i" if tx_proba >= 0.5 else "X·ªâu"
    cl_proba, cl_probs = predict_stacking(X_pred, models, 'cl')
    cl = "Ch·∫µn" if cl_proba >= 0.5 else "L·∫ª"
    dai_diem = suggest_best_totals(df, tx)
    bao_proba, bao_probs = predict_stacking(X_pred, models, 'bao')
    bao_pct = round(bao_proba*100,2)

    # L∆∞u l·∫°i d·ª± ƒëo√°n v√†o DB ƒë·ªÉ so s√°nh ƒë√∫ng/sai
    insert_result("BOT_PREDICT", None, tx)

    so_du_doan, dung, sai, tile = summary_stats(df)
    lines = []
    lines.append(f"‚úîÔ∏è ƒê√£ l∆∞u k·∫øt qu·∫£: {''.join(str(n) for n in numbers)}")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"üéØ D·ª± ƒëo√°n: {tx} | {cl}")
    else:
        lines.append("‚ö†Ô∏è D·ª± ƒëo√°n: N√™n ngh·ªâ phi√™n n√†y!")
    lines.append(f"D·∫£i ƒëi·ªÉm n√™n ƒë√°nh: {dai_diem}")
    lines.append(f"X√°c su·∫•t ra b√£o: {bao_pct}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_ALERT:
        lines.append(f"‚ùóÔ∏èC·∫¢NH B√ÅO: X√°c su·∫•t {tx} v∆∞·ª£t {int(PROBA_ALERT*100)}% ‚Äì trend c·ª±c m·∫°nh!")
    if bao_proba >= BAO_CUTOFF:
        lines.append(f"‚ùóÔ∏èC·∫¢NH B√ÅO: X√°c su·∫•t b√£o cao ({bao_pct}%) ‚Äì c√¢n nh·∫Øc v√†o b√£o!")
    lines.append(f"BOT ƒë√£ d·ª± ƒëo√°n: {so_du_doan} phi√™n | ƒê√∫ng: {dung} | Sai: {sai} | T·ªâ l·ªá ƒë√∫ng: {tile}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"Nh·∫≠n ƒë·ªãnh: ∆Øu ti√™n {tx}, {cl}, d·∫£i {dai_diem}. B√£o {bao_pct}% ‚Äì {'∆∞u ti√™n' if bao_proba >= BAO_CUTOFF else 'kh√¥ng n√™n ƒë√°nh'} b√£o.")
    else:
        lines.append("Nh·∫≠n ƒë·ªãnh: Kh√¥ng c√≥ c·ª≠a ∆∞u th·∫ø, n√™n ngh·ªâ.")
    await update.message.reply_text('\n'.join(lines))

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    msg = (
        "ü§ñ Ch√†o m·ª´ng ƒë·∫øn v·ªõi Sicbo ML Bot!\n\n"
        "C√°c l·ªánh h·ªó tr·ª£:\n"
        "/start ‚Äì Xem h∆∞·ªõng d·∫´n v√† danh s√°ch l·ªánh\n"
        "/predict ‚Äì D·ª± ƒëo√°n phi√™n ti·∫øp theo\n"
        "/stats ‚Äì Th·ªëng k√™ hi·ªáu su·∫•t d·ª± ƒëo√°n\n"
        "/reset ‚Äì X√≥a to√†n b·ªô l·ªãch s·ª≠ data (c·∫ßn x√°c nh·∫≠n)\n\n"
        "Nh·∫≠p 3 s·ªë k·∫øt qu·∫£ (vd: 456 ho·∫∑c 4 5 6) ƒë·ªÉ l∆∞u v√† c·∫≠p nh·∫≠t model."
    )
    await update.message.reply_text(msg)

async def predict(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000)
    if len(df) < MIN_BATCH:
        await update.message.reply_text("Ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ d·ª± ƒëo√°n. H√£y nh·∫≠p th√™m k·∫øt qu·∫£!")
        return
    df_feat = make_features(df)
    train_models(df_feat)
    models = load_models()
    if (models is None or 
        models['tx'] is None or
        models['cl'] is None or
        models['bao'] is None):
        await update.message.reply_text("‚ö†Ô∏è Ch∆∞a ƒë·ªß d·ªØ li·ªáu ƒëa d·∫°ng ƒë·ªÉ d·ª± ƒëo√°n (l·ªãch s·ª≠ m·ªõi ch·ªâ c√≥ 1 lo·∫°i k·∫øt qu·∫£). Nh·∫≠p th√™m c·∫£ T√†i/X·ªâu, Ch·∫µn/L·∫ª, B√£o/Kh√¥ng b√£o ƒë·ªÉ bot ho·∫°t ƒë·ªông ch√≠nh x√°c!")
        return
    X_pred = df_feat.iloc[[-1]][['total', 'even', 'tai_roll', 'xiu_roll', 'chan_roll', 'le_roll', 'bao_roll']]
    tx_proba, _ = predict_stacking(X_pred, models, 'tx')
    cl_proba, _ = predict_stacking(X_pred, models, 'cl')
    tx = "T√†i" if tx_proba >= 0.5 else "X·ªâu"
    cl = "Ch·∫µn" if cl_proba >= 0.5 else "L·∫ª"
    dai_diem = suggest_best_totals(df, tx)
    bao_proba, _ = predict_stacking(X_pred, models, 'bao')
    bao_pct = round(bao_proba*100,2)
    insert_result("BOT_PREDICT", None, tx)
    so_du_doan, dung, sai, tile = summary_stats(df)
    lines = []
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"üéØ D·ª± ƒëo√°n: {tx} | {cl}")
    else:
        lines.append("‚ö†Ô∏è D·ª± ƒëo√°n: N√™n ngh·ªâ phi√™n n√†y!")
    lines.append(f"D·∫£i ƒëi·ªÉm n√™n ƒë√°nh: {dai_diem}")
    lines.append(f"X√°c su·∫•t ra b√£o: {bao_pct}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_ALERT:
        lines.append(f"‚ùóÔ∏èC·∫¢NH B√ÅO: X√°c su·∫•t {tx} v∆∞·ª£t {int(PROBA_ALERT*100)}% ‚Äì trend c·ª±c m·∫°nh!")
    if bao_proba >= BAO_CUTOFF:
        lines.append(f"‚ùóÔ∏èC·∫¢NH B√ÅO: X√°c su·∫•t b√£o cao ({bao_pct}%) ‚Äì c√¢n nh·∫Øc v√†o b√£o!")
    lines.append(f"BOT ƒë√£ d·ª± ƒëo√°n: {so_du_doan} phi√™n | ƒê√∫ng: {dung} | Sai: {sai} | T·ªâ l·ªá ƒë√∫ng: {tile}%")
    if max(tx_proba, 1-tx_proba) >= PROBA_CUTOFF:
        lines.append(f"Nh·∫≠n ƒë·ªãnh: ∆Øu ti√™n {tx}, {cl}, d·∫£i {dai_diem}. B√£o {bao_pct}% ‚Äì {'∆∞u ti√™n' if bao_proba >= BAO_CUTOFF else 'kh√¥ng n√™n ƒë√°nh'} b√£o.")
    else:
        lines.append("Nh·∫≠n ƒë·ªãnh: Kh√¥ng c√≥ c·ª≠a ∆∞u th·∫ø, n√™n ngh·ªâ.")
    await update.message.reply_text('\n'.join(lines))

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    df = fetch_history(10000)
    so_du_doan, dung, sai, tile = summary_stats(df)
    msg = (
        f"BOT ƒë√£ d·ª± ƒëo√°n: {so_du_doan} phi√™n\n"
        f"ƒê√∫ng: {dung}\n"
        f"Sai: {sai}\n"
        f"T·ªâ l·ªá ƒë√∫ng: {tile}%"
    )
    await update.message.reply_text(msg)

async def reset(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    PENDING_RESET[user_id] = True
    await update.message.reply_text(
        "‚ö†Ô∏è B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a to√†n b·ªô l·ªãch s·ª≠ data? "
        "N·∫øu ch·∫Øc ch·∫Øn, reply: X√ìA H·∫æT\n"
        "N·∫øu kh√¥ng, nh·∫≠p b·∫•t k·ª≥ k√Ω t·ª± n√†o kh√°c ƒë·ªÉ h·ªßy."
    )

def main():
    create_table()
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("predict", predict))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(CommandHandler("reset", reset))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    app.run_polling()

if __name__ == "__main__":
    main()
